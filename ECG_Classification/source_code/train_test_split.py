import os
from tqdm import tqdm #tqdm dÃ¹ng Ä‘á»ƒ hiá»‡n progress bar khi xá»­ lÃ½ nhiá»u áº£nh
import concurrent.futures
from functools import partial
import shutil
from sklearn.model_selection import train_test_split
from concurrent.futures import ThreadPoolExecutor


# ÄÆ°á»ng dáº«n gá»‘c chá»©a 4 folder class
SOURCE_DIR = "E:/pv/WORKING/ECG_main_folder/ECG_Classification/data/processed_images"  
TRAIN_DIR = "E:/pv/WORKING/ECG_main_folder/ECG_Classification/data/train_images"
TEST_DIR = "E:/pv/WORKING/ECG_main_folder/ECG_Classification/data/test_images"
SPLIT_RATIO = 0.8  # 80% train, 20% test

# BÆ°á»›c 1: Láº¥y toÃ n bá»™ danh sÃ¡ch áº£nh vÃ  nhÃ£n
all_images = [] # list Ä‘á»ƒ chá»©a Ä‘Æ°á»ng dáº«n cÃ¡c áº£nh trong file gá»‘c 
all_labels = [] # list Ä‘á»ƒ chá»©a cÃ¡c label  (0, 1, 2, 3)

for label in os.listdir(SOURCE_DIR):
    label_path = os.path.join(SOURCE_DIR, label)
    if os.path.isdir(label_path):  # Chá»‰ xá»­ lÃ½ náº¿u lÃ  folder
        for filename in os.listdir(label_path): # Duyá»‡t qua tá»«ng file áº£nh
            image_path = os.path.join(label_path, filename)
            all_images.append(image_path) # ThÃªm áº£nh vÃ o danh sÃ¡ch
            all_labels.append(label)   # GÃ¡n nhÃ£n tÆ°Æ¡ng á»©ng

# BÆ°á»›c 2: Stratified split chia theo tá»‰ lá»‡ 80 20 
train_imgs, test_imgs, train_labels, test_labels = train_test_split(
    all_images, all_labels, test_size=1 - SPLIT_RATIO, stratify=all_labels, random_state=4
)

# BÆ°á»›c 3: HÃ m copy áº£nh sang thÆ° má»¥c Ä‘Ã­ch
def copy_image(img_path, label, target_root):
    label_dir = os.path.join(target_root, label) # Táº¡o Ä‘Æ°á»ng dáº«n tá»›i folder class
    os.makedirs(label_dir, exist_ok=True)  
    filename = os.path.basename(img_path) # Láº¥y tÃªn file gá»‘c
    save_path = os.path.join(label_dir, filename) # ÄÆ°á»ng dáº«n lÆ°u áº£nh

    shutil.copy(img_path, save_path) #shutil.copy Ä‘á»ƒ sao chÃ©p áº£nh tá»« gá»‘c sang thÆ° má»¥c má»›i

# BÆ°á»›c 4: HÃ m dÃ¹ng song song Ä‘á»ƒ copy nhiá»u áº£nh nhanh
def copy_images_parallel(images, labels, target_root, max_workers=8):
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        list(tqdm(executor.map(lambda args: copy_image(*args), zip(images, labels, [target_root]*len(images))), total=len(images)))

# BÆ°á»›c 5: Tiáº¿n hÃ nh copy song song
print("ğŸ“‚ Copy train images...")
copy_images_parallel(train_imgs, train_labels, TRAIN_DIR)

print("ğŸ“‚ Copy test images...")
copy_images_parallel(test_imgs, test_labels, TEST_DIR)

print(f"\nâœ… Done! Train: {len(train_imgs)} áº£nh | Test: {len(test_imgs)} áº£nh")
